{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers, Dense, Input, InputLayer, Flatten\n",
    "# from tensorflow.keras.models import Sequential, Model\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision.transforms as tt\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.datasets import load_files\n",
    "\n",
    "%matplotlib inline\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data paths\n",
    "bins_path = r\"..\\data\\bins\"\n",
    "nonbins_path = r\"..\\data\\non-bins\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all images to the same file format\n",
    "def convert_img_type(to_type, dir, prefix):\n",
    "    for i, filename in enumerate(os.listdir(dir)):\n",
    "        name = f\"{prefix}{'{:03}'.format(i)}.{to_type}\"\n",
    "        if not filename.endswith(f\".{to_type}\"):\n",
    "            old_file_path = osp.join(dir, filename)\n",
    "            img = Image.open(old_file_path)\n",
    "            rgb_img = img.convert(\"RGB\")\n",
    "            img.close()\n",
    "            rgb_img.save(osp.join(dir, name), quality=300)\n",
    "            rgb_img.close()\n",
    "            os.remove(old_file_path)\n",
    "        else:\n",
    "            os.rename(osp.join(dir, filename), osp.join(dir, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_img_type(\"png\", bins_path, \"bin_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_img_type(\"png\", nonbins_path, \"nonbin_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview data\n",
    "def data_preview(dir):\n",
    "    print(f\"{osp.basename(dir)} data preview:\")\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    for i in range(5):\n",
    "        file = random.choice(os.listdir(dir))\n",
    "        image_path = os.path.join(dir, file)\n",
    "        img = mpimg.imread(image_path)\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        ax.title.set_text(file)\n",
    "        plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preview(bins_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preview(nonbins_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute min image dimensions\n",
    "# def compute_dims(classes):\n",
    "#     dim = sys.maxsize\n",
    "#     for dir in classes:\n",
    "#         for file in os.listdir(dir):\n",
    "#             img = Image.open(osp.join(dir, file))\n",
    "#             dim = min(dim, min(img.size))\n",
    "\n",
    "#     return dim\n",
    "\n",
    "\n",
    "# dim = compute_dims([bins_path, nonbins_path])\n",
    "# print(f\"Min image dimensionw: {dim}x{dim}\")\n",
    "\n",
    "dim = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and resize images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images to min dimensions and center crop them\n",
    "for dir in [bins_path, nonbins_path]:\n",
    "    for file in os.listdir(dir):\n",
    "        img = Image.open(osp.join(dir, file))\n",
    "        resize = tt.functional.resize(img, dim)\n",
    "        crop = tt.functional.center_crop(resize, dim)\n",
    "        crop.save(osp.join(dir, file), quality=300)\n",
    "        img.close()\n",
    "        resize.close()\n",
    "        crop.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.stack(\n",
    "    [\n",
    "        cv2.imread(osp.join(bins_path, x), cv2.IMREAD_GRAYSCALE)\n",
    "        for x in os.listdir(bins_path)\n",
    "    ]\n",
    ")\n",
    "nonbins = np.stack(\n",
    "    [\n",
    "        cv2.imread(osp.join(nonbins_path, x), cv2.IMREAD_GRAYSCALE)\n",
    "        for x in os.listdir(nonbins_path)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate([bins, nonbins])\n",
    "y = np.asarray([1] * len(bins) + [0] * len(nonbins))\n",
    "X = np.array(images, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=4\n",
    ")\n",
    "X_train = X_train.reshape(-1, dim, dim, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the CNN\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import Input, datasets, layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for CNN model\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "save_dir = os.path.join(\"..\", \"models\")\n",
    "model_name = \"bin-identifier.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    ModelCheckpoint(\n",
    "        filepath=osp.join(save_dir, \"best_model.h5\"),\n",
    "        monitor=\"loss\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    TensorBoard(log_dir=osp.join(\"..\", \"logs\")),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(dim, dim, 1)\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.BatchNormalization(axis=-1),\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.BatchNormalization(axis=-1),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(rate=0.5),\n",
    "        tf.keras.layers.Dense(1, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, decay=learning_rate / (epochs * 0.5)\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
    "\n",
    "\n",
    "aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "\n",
    "# X_train = tf.random.normal((50, dim, 256, 3))\n",
    "# y_train = tf.random.uniform((50,), maxval=3, dtype=tf.int32)\n",
    "history = model.fit(\n",
    "    aug.flow(X_train, y_train, batch_size=2), epochs=epochs, callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\", \"mse\"]\n",
    ")\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv-hackathon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "896db0e8bfd5b97d8b8f58ed518bc63d99bd613727e9ea27f7aa81e14de83c8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
